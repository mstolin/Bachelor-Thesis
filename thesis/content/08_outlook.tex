\chapter{Conclusion and Outlook}
\label{chap:08_outlook}

In this chapter , an outlook is given for further research based on the results of \Chap{chap:07_evaluation}.


% ===========================================
% ===========================================
\section{Conclusion}
% Intro
In this thesis, a scalable computing environment for training machine learning models using Apache Spark was implemented. In addition, the training process is automated using an automated deployment pipeline.
% The research questions
In CHAPTER 1, three research questions and the  for this thesis are defined.


% RQ1
The first research question is about how to implement a solution to automatically scale the number of workers in an Apache Spark cluster.
% The solution
For this research question, a computing environment according to autonomic computing architecture  is implemented.
% Autonomic computing
It consists of an autonomic manager and an Apache Spark cluster.
% Docker
For simplicity, all components of the computing environment were deployed with Docker.
% manager
The autonomic manager is implemented in accordance to the MAPE architecture and responsible to monitor and automatically scale the Apache Spark workers.
% monitoring system
For the implementation of the autonomic manager, Prometheus, cadvisor, and DCGM-Exporter are used to create a monitoring system.
% Auto-Scaler
In addition, an \textit{Auto-Scaler} is implemented using Python 3 that automatically fetches performance metrics from the monitoring system and scales the Apache Spark workers.
% Results
%The evaluation shows, that the \textit{Auto-Scaler} implementation was not able to improve the performance of the computing environment. Furthermore, the \textit{Auto-Scaler} caused an increase of the spark-job execution time.


% RQ2
The second research question is about how to accelerate the computational power of the Apache Spark cluster using GPUs.
% RAPIDS
The solution for this research question is implemented by extending the existing Apache Spark cluster with the NVIDIA RAPIDS Accelerator for Apache Spark plugin.
%
The impact of GPUs have been tested using a classification and a regression benchmark. For the experiments, 2 GPUs have been available. 
% results
%The evaluation results show, that 2 GPU-accelerated Apache Spark worker are able to outperform 2 CPU-only Apache Spark worker by 2.42x for the classification benchmark and 3.02x for the regression benchmark.


% RQ3
The final research question is about how to automate the training of a machine learning model.
%
To accommodate this research question, a CI pipeline is implemented using GitLab CI/CD. The CI pipeline is performed when a change is committed to the machine learning applications source code.
% How
It consists of a \textit{train-stage} which automatically deploys a \textit{spark-submit} Docker container to the Apache Spark cluster.
% spark-submit
The \textit{spark-submit} container executes the spark-submit executable to perform the application on the Apache Spark cluster.
% Gitlab runner
To able to deploy a \textit{spark-submit} container from the \textit{train-stage} inside the Apache Spark cluster, a GitLab Runner is created which runs in the same host.


% Results
The impact of a GPU-accelerated Apache Spark cluster and of the \textit{Auto-Scaler} are evaluated with two different machine learning algorithms.
% GPU results
The results show, that enabling Apache Spark to use GPUs improved the spark-job execution time significantly.
% Auto-Scaler
However, the implementation of the \textit{Auto-Scaler} is not able to improve the spark-job execution time. Furthermore, the execution time increases by enabling the \textit{Auto-Scaler} in the cluster.


% ===========================================
% ===========================================
\section{Outlook}
% Intro
The implementation of the \textit{Auto-Scaler} was not able to improve the performance of training machine learning models on the Apache Spark cluster.
% A possible reason
A possible reason for the execution time increase is, that Apache Spark is not able to efficiently distribute the workload of an application while workers are added to cluster during the execution of an application.
% Differet approaches
Therefore, different \textit{Auto-Scaler} implementations approaches for further research are introduced.


\subsection{Reactive Auto-Scaler Approach}
% Currently
The current implementation of the \textit{Auto-Scaler} follows a proactive approach. It uses static threshold-based rules (e.g., maximum and minimum CPU utilization) to define when a scaling action is necessary.
% Not sufficient
The \textit{Auto-Scaler} can be optimized using a reactive approach with dynamic thresholds. A proactive \textit{Auto-Scaler} tries to predict the future state of the computing environment (e.g. reinforcement learning) using historical data.
The MAPE architecture can be extended using a knowledge-base to save historicial data and us it in the analyse phase ...


\subsection{Vertical Scaling Approach}
% evaluations
The evaluation of the static CPU-only workers experiment showed, that from a specific number of workers no significant performance improvement is made.
% vertical
Therefore, instead of scaling the replicas of worker nodes, a vertical-scaling approach for the \textit{Auto-Scaler} should be explored. The Auto-Scaler would then scale the available resources for an executor.
% results
Providing more powerful resources increases the computational power of the Apache Spark cluster and should lead to lower execution times for training machine learning models.


\subsection{Automatically GPUs}
\label{subsec:08_outlook_gpus}
% Currently no GPUs
Due to ..
The \textit{Auto-Scaler} was not able to be evaluated using GPU-accelerated workers because it is not able to distribute GPUs exclusivley for each worker.
% GPU approach
Extending the Auto-Scaler to be able to keep track of GPUs which are free or already allocated by a worker should be explored.
%
Auto-scaling GPU-accelerated worker nodes can cause an improvement of the spark-job execution time.


\subsection{Shuffle bla bla}
As mentioned in SECTION DESIGN ODER IMPL, the current approach is, that no worker nodes are removed while applications re actively performed.
% Why
Worker nodes cant be removed while applications are performed because each participating worker, keeps temporary data. If a node is removed, the application will not succeed.
%
To remove worker while applications are perform to prevent over-provisioning, an external shuffle service is needed. This enabled worker to store temporary data on an external node which is available across all worker nodes.
% blacklisting
Additional it is necessary to blacklist nodes which will be removed, so no executor will be deployed on that node.
%
Zeus, apaches external shuffle service.
