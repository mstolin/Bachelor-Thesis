\chapter{Outlook}
\label{chap:08_outlook}

In this chapter , an outlook is given for further research based on the results of \Chap{chap:07_evaluation}.


% ===========================================
% ===========================================
\section{Scaling}
% Intro
The results of SECTION XY show that, the implementation of the Auto-Scaler is nit sufficient for scaling Apache Spark worker nodes. Furthermore, it has increased the overall execution time for a spark-job.


% Reasons
A possible reason for this is result is, that Apache Spark is not able to efficiently distribute the workload between existing worker nodes and newly created worker nodes.
% a solution
A solution for this problem is, to activate worker nodes when they are needed instead of deploying new nodes. Apache Spark supports to blacklist worker nodes to creates executors.
% the concept
Then, instead of deploying new worker nodes, the Auto-Scaler whitelists a specific number of already existing worker.


% Reactive scaler
The current design of the Auto-Scaler follows a proactive approach by responding to the current status of the computing environment (see SEC RELATED WORK).
% pro active
The efficiency of the Auto-Scaler can be optimized by following a reactive approach. Then the Auto-Scaler uses techniques to predict the future state of the computing environment.
% MAPE-K
The MAPE architecture used for the autonomic manager can be extended to gain knowledge (MAPE-K).
% reinformcement learning
The knowledge can be used to predict the future state of the computing environment using reinforcement-learning models.


% scaling executor
In the experiment of CHAP EVAL, all workers only executed their work on one executor.
% another approach
The number of executors can be scaled as well.
% Rapids
In accordance with the RAPIDS plugin, for each executor 1 GPU has to be available.



% Vertical scaling
Another approach to scale the performance of Apache Spark worker is vertical scaling.
% in this thesis
In this thesis, the horizontal scaling approach is used to scale the number of actively performing worker nodes.
%
By using the vertical scaling approach, the resources of executors can be scaled. This can have the effect, that a worker is able to compute faster.


% ===========================================
% ===========================================
\section{Shuffle bla bla}
As mentioned in SECTION DESIGN ODER IMPL, the current approach is, that no worker nodes are removed while applications re actively performed.
% Why
Worker nodes cant be removed while applications are performed because each participating worker, keeps temporary data. If a node is removed, the application will not succeed.
%
To remove worker while applications are perform to prevent over-provisioning, an external shuffle service is needed. This enabled worker to store temporary data on an external node which is available across all worker nodes.
% blacklisting
Additional it is necessary to blacklist nodes which will be removed, so no executor will be deployed on that node.
%
Zeus, apaches external shuffle service.
