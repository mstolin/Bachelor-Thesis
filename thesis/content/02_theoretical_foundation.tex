\chapter{Theoretical Foundation}
\label{chap:02_foundation}


This chapter provides the theoretical foundation about concepts that will be used in this thesis. The concepts describes in this chapter provide the foundation to understand the choice of the all tools. In addition to understand the conceptual design.


\section{Scalability}
% What is scalability
Scalability defines the ability of a computing system to handle an increasing amount of load \cite{Farcic2017Toolkit21}.
% Why scaling
The main reasing for scaling is High-Availability TOOLKIT 2.1.
% Choose right approach
To choose the right approach of scaling an environment is essential.
% Different kind of scaling
To scale the computing capacity of a system, different approaches exists. A major scaling approach is horizontal scaling.

%% Mehr darüber, warum scaling eigentlich so wichtig ist, und welche probleme man damit löst


\subsection{Horizontal Scaling}
% What is horizontal scaling
Horizontal scaling is accomplished by duplicating nodes in the computing environment \cite{Wilder2012CloudPatterns}.
% DIstribution
Dplucation the nodes in a computing environment increases the computational capacity of the environment. In addition, the workload can be distributed across all clones to handle and balance and increasing load of tasks \cite{Wilder2012CloudPatterns, Abbott2015ScalabilityArt}. 
% What about homogeneous nodes
To increase the efficiency of horizontal scaling, all nodes should be homogeneous. Homogeneous nodes are able to perform the same work and response as other nodes \cite{Abbott2015ScalabilityArt}.


\subsection{Limitations of Scalability}
The limit of scalability is reached, when a computing system is not able to serve the requests of it`s concurrent users \cite{Wilder2012CloudPatterns}.
% hardware capacity
If the scalability of a computing environment is reached, an option is to add more powerful hardware resources to the system. This approach is called vertical scaling QULLE??. By adding more powerful hardware resources, the point can be reached, where more powerful hardware becomes unaffordable or not available \cite{Wilder2012CloudPatterns}.
% Why horizontal i recommended
To overcome the limits of hardware cpacity, a computing system shuld be designed to scale horizontally in the first place \cite{Abbott2015ScalabilityArt}.


% ===========================================
% ===========================================
\section{Deployment Pipeline}
% Short Abstract
A deployment pipeline is an implementation of the process for getting software from source code to production.
% Based on CI
It is based on the concept of Continuous Integration (CD) and Continuous Delivery (CD).
% Involves what
The process involves building, testing and deploying software through automated scripts \cite{Farley2010CI}.


% Advantages


%\begin{figure}[h]
%\centering
%\includegraphics[scale=1]{images/02_theoretical_foundation/ci_cd/ci_cd_phases}
%\caption{Autonomic computing concept - Source: Authors own model, based on \cite{Jacob2004AutonomicSolution}.}
%\label{fig:02_foundation_ci-cd_phases}
%\end{figure}


\subsection{Continuous Integration}
% Abtract def
Continuous Integration is a development practice where each change on a primary code base is validated by automated scripts. This ensures that errors are detected and fixed in an early development stage \cite{Duvall2007CI}.
% FIrst part
CI is the first process in a deployment pipeline.
% What its about
This process is responsible for building, testing and validating the software to guarantee that the software is in a deployable state at all time \cite{Rossel2017CICD}.
% Advantages
A CI process contributes with the following advantages to the development life cycle of an application:
\begin{itemize}
\item \textbf{Reduce risks:}
Because the CI process will run tests and validations on each change, errors will be detected in an early stage and can be fixed immediately \cite{Duvall2007CI}.

\item \textbf{Reduce manual processes:} 
% Same time
The CI process will perform every time a commit has being made to the code base.
% Same process
Each run is processed the exact same way every time.
% No human
Therefore, no human intervention is needed to start the process which saves time and cost \cite{Duvall2007CI}.

\item \textbf{Generate deployable software:}
If an error occurs during a CI run, developers will be informed and fixes can be applied immediately.
This ensures that the software is in a deployable state at time \cite{Duvall2007CI}.
\end{itemize}


\subsubsection{Requirements of a Continuous Integration Process}
% Requirements
The implementation of a CI process is based on several requirements:
% The list
\begin{enumerate}
\item \textbf{Version control repository:}
To manage changes to the code base, the source code and all other assets like the build script should be hosted on a single version control repository.
% Changes
Each change on the code base will trigger the CI process on the build server to run against the latest version available \cite{Duvall2007CI}.

\item \textbf{Build server:}
The build server is responsible to monitor the code base for changes.
% Execute
If a change has been committed, the build server automatically executes the CI scripts in order \cite{Rossel2017CICD, Duvall2007CI}.

\item \textbf{Build script:}
This includes all automation scripts to build, test and validate the source code \cite{Duvall2007CI}.
\end{enumerate}


\subsubsection{Continuous Integration Process Example}
% BLA BLA


\subsection{Continuous Delivery}
After the CI pipeline has succeeded, a CD pipeline is responsible to deploy the artefact to a production server \cite{Rossel2017CICD}.
% Advantages of a cd pipeline


% ===========================================
% ===========================================
\section{Autonomic Computing}
\label{sec:02_ac}
% What is autonomic computing
Autonomic computing is the ability of an IT infrastructure to automatically manage itself in accordance to high level objectives defined by administrators \cite{Kephart2003VisionComputing}.
% Why
Autonomic computing gives an IT infrastructure the flexibility to adapt dynamic requirements quickly and effectively to meet the challenges of modern business needs \cite{Murch2004Autonomic}. Therefore, autonomic computing environments can reduce operating costs, lower failure rates, make systems more secure and quickly respond to business needs \cite{Jacob2004AutonomicSolution}.


% What does it need
Computing systems need to obtain a detailed knowledge of it`s environment and how to extend it`s resources to be truly autonomic \cite{Murch2004Autonomic}.
% The 4 basic elements
An autonomic computing system is defined by four elements:
\begin{itemize}
\item \textbf{Self-configuring:}
Self-configuring refers to the ability of an IT environment to adapt dynamically to system changes and to be able to deploy new components automatically. Therefore, the system needs to understand and control the characteristics of a configurable item \cite{Murch2004Autonomic, Sinreich2006AnAB}.

\item \textbf{Self-optimizing:}
To ensure given goals and objectives, a self-optimizing environment has the ability to efficiently maximize resource allocation and utilization \cite{Jacob2004AutonomicSolution}. To accomplish this requirement, the environment has to monitor all resources to determine if an action is needed \cite{Murch2004Autonomic}.

\item \textbf{Self-healing:}
Self-healing environments are able to detect problematic operations and then perform policy-based actions to ensure that the systems health is stable \cite{Sinreich2006AnAB, Jacob2004AutonomicSolution}. The policies of the actions have to be defined and should be executed without disrupting the system \cite{Sinreich2006AnAB, Jacob2004AutonomicSolution}.

\item \textbf{Self-protecting:}
The environment must identify unauthorized access and threats to the system and automatically protect itself taking appropriate actions during its runtime \cite{Sinreich2006AnAB, Jacob2004AutonomicSolution}.
\end{itemize}


\subsection{Autonomic Computing Concept}

% Concept figure
\begin{figure}[h]
\centering
\includegraphics[scale=1]{images/02_theoretical_foundation/autonomic_computing/autonomic_computing_concept}
\caption{Autonomic computing concept - Source: Authors own model, based on \cite{Jacob2004AutonomicSolution}.}
\label{fig:ac_concept}
\end{figure}

% Figure + short description
\Fig{fig:ac_concept} demonstrates the main concept of an autonomic computing environment. The autonomic computing architecture relies on monitoring sensors and an adoption engine (autonomic manager) to manage resources in the environment \cite{Goscinski2011CloudComputing}.
% About the environment
In an autonomic computing environment, all components have to communicate to each other and can manage themselves. Appropriate decisions will be made by an autonomic manager that knows the given policies \cite{Jacob2004AutonomicSolution}.

% Control loop figure
\begin{figure}[h]
\centering
\includegraphics[scale=1]{images/02_theoretical_foundation/autonomic_computing/control_loop}
\caption{The control-loop concept - Source: Authors own model, based on \cite{Murch2004Autonomic}.}
\label{fig:ac_control_loop}
\end{figure}

% Explain control loop
The core element of the autonomic architecture is the control-loop. \Fig{fig:ac_control_loop} illustrates the concept of a control-loop. The control-loop collects details about resources through monitoring and makes decisions based on analysis of the collected details to adjust the system if needed \cite{Murch2004Autonomic}.


\subsection{Managed Resources}

% Figure
\begin{figure}[h]
\centering
\includegraphics[scale=1]{images/02_theoretical_foundation/autonomic_computing/managed_resource}
\caption{Managed resource - Source: Authors own model, based on \cite{Jacob2004AutonomicSolution}.}
\label{fig:ac_managed_resource}
\end{figure}

% Explanation
A managed resource is a single component or a combination of components in the autonomic computing environment \cite{Murch2004Autonomic, Jacob2004AutonomicSolution}. A component can be a hardware or software component, e.g. a database, a server, an application or a different entity \cite{Sinreich2006AnAB}.
% Sensors and Effectors
They are controlled by their sensors and effectors, as illustrated in \Fig{fig:ac_managed_resource}. Sensors are used to collect information about the state of the resource and effectors can be used to change the state of the resource \cite{Jacob2004AutonomicSolution}. The combination of sensors and effectors is called a touchpoint, which provides an interface for communication with the autonomic manager \cite{Sinreich2006AnAB}.
% Scalability
The ability to manage and control managed resources make them highly scalable \cite{Murch2004Autonomic}.


\subsection{Autonomic Manager}
\label{subsec:02_ac_manager}

% Figure
\begin{figure}[h]
\centering
\includegraphics[scale=1]{images/02_theoretical_foundation/autonomic_computing/autonomic_manager}
\caption{Autonomic manager - Source: Authors own model, based on \cite{Jacob2004AutonomicSolution}.}
\label{fig:ac_manager}
\end{figure}

% WHat is the autonomic manager
The autonomic manager implements the control-loop to collect, aggregate, filter and report system metrics from the managed resources. It can only make adjustments within it`s own scope and uses predefined policies to make decisions of what actions have to be executed to accommodate the goals and objectives \cite{Murch2004Autonomic, Sinreich2006AnAB}.
% Knowledge
In addition, the autonomic manager gains knowledge through analyzing the managed resources \cite{Murch2004Autonomic}.
% MAPE-K
The autonomic computing concept digests the MAPE-K model to implement an autonomic manager, as illustrated in \Fig{fig:ac_manager} \cite{Goscinski2011CloudComputing}.

\begin{itemize}
\item \textbf{Monitor:}
The monitor phase is responsible to collect the needed metrics from all managed resources and applies aggregation and filter operations to the collected data \cite{Sinreich2006AnAB}.

\item \textbf{Analyze:}
The autonomic manager has to gain knowledge to determine if changes have to made to the environment \cite{Sinreich2006AnAB}. To predict future situations, the autonomic manager can model complex situation given the collected knowledge \cite{Jacob2004AutonomicSolution}.

\item \textbf{Plan:}
Plans have to be structured to achieve defined goals and objectives. A plan consists of policy-based actions \cite{Jacob2004AutonomicSolution, Sinreich2006AnAB}.

\item \textbf{Execute:}
The execute phase applies all necessary changes to the computing system \cite{Sinreich2006AnAB}.
\end{itemize}

% Multiple manager
Multiple autonomic manager can exist in an autonomic computing environment to perform only certain parts. For example, there can be one autonomic manager which is responsible to monitor and analyse the system and another autonomic manager to plan and execute. To create a complete and closed control-loop, multiple autonomic manager can be composed together \cite{Sinreich2006AnAB}.


% ===========================================
% ===========================================
\section{System Performance}


\subsection{Performance Metrics}
% Short description
Performance metrics are statistics that describe the system performance. These statistics are generated by the system, applications or other tools \cite{Greg2020SysPerf}.
% Common types
The following are examples of common types for performance metrics:
\begin{itemize}
\item \textbf{Throughput:} Volume of data or operations per second \cite{Greg2020SysPerf}.
\item \textbf{Latency:} Time of operation \cite{Greg2020SysPerf}.
\item \textbf{Utilization:} Usage of a component \cite{Greg2020SysPerf}.
\end{itemize}


% Overhead
\paragraph{}Measuring performance metrics can cause an overhead. To gather and store performance metrics, CPU cycles must be spent. This can have a negative affect on the target performance \cite{Greg2020SysPerf}.


\subsection{Time-Based Utilization}
% What is utilization
Utilization is a performance metrics that describes the usage of a device, e.g. CPU device usage.
% What about time-based utilization
A time-based utilization describes the usage of a component during a time period where the component was actively performing work \cite{Greg2020SysPerf}.
% 100% utilization
When a resource approaches 100\% utilization, the performance of that resource can degrade. If a component can process operations in parallel, the performance does not have to degrade much at 100\% utilization and the component can process more work \cite{Greg2020SysPerf}.


% ===========================================
% ===========================================
\section{Monitoring}
\label{sec:02_monitoring}
% What is monitoring
Monitoring is a process, that aims to detect and take care of system faults. In a dynamic environment, becoming aware of the system is trivial \cite{Ligus2012EffMonitoring}.
% What is a monitoring system
A monitoring system consists of a set of different tools. The tools are responsible to perform measurements on components in the computing environment and collect, store and interpret the monitored data \cite{Ligus2012EffMonitoring}. 


% The monitoring Loop/Process
\begin{figure}[h]
\centering
\includegraphics[scale=0.9]{images/02_theoretical_foundation/monitoring/monitoring_system}
\caption{The monitoring process - Source: Authors own model.}
\label{fig:mon_mon-system-process}
\end{figure}
In the monitoring process, illustrated in \Fig{fig:mon_mon-system-process}, data is continuously collected by agents. An agent is a process that continuously gathers metrics. Data can be device statistics, logs or system measurements. Agents will group these data into metrics and submit them to the monitoring system via a protocol. The monitoring system will store the metrics in its database \cite{Ligus2012EffMonitoring}.


% Requirements of a monitoring system
The requirements for a monitoring system, that is able to monitor a dynamic changing environment, are the following:
\begin{itemize}
\item An efficient database to store metrics
\item A push or pull based way of gathering metrics \cite{Farcic2017Toolkit21}
\item Multi-dimensional metrics \cite{Farcic2017Toolkit21}
\item A powerful query language \cite{Farcic2017Toolkit21}
\end{itemize}


\subsection{Database}
% Continuous data
Continuous data needs to be stored in the most efficient way.
% TSDB
Time-series databases (TSDB) are optimized to store and retrieve time-series data.
% Format
In a time-series database, metrics will be stored in a compact and optimized format. This allows the database to store a massive amount of time-series data on a single machine.


\subsection{Push and Pull}
\label{subsec:02_monitoring_push-pull}
The approach how the monitoring systems gathers metrics to store in the database plays a significant role.
% There are push and pull based systems
Push and pull based systems are the two primary approaches to gather metrics from services.
% About push
Push based monitoring systems expect services to push metrics to their storage.
% About pull
On the other hand, pull based monitoring systems scrape metrics from all defined targets. Targets do not know about the existence of the monitoring system and only need to collect and expose metrics \cite{Farcic2017Toolkit21}.


% When to choose what (Discovery)
Service discovery is an important aspect to decide whenever to use a pull or push based monitoring system \cite{Farcic2017Toolkit21}.

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{images/02_theoretical_foundation/monitoring/push_based}
\caption{Push-based monitoring approach - Source: Authors own model.}
\label{fig:mon_push-based}
\end{figure}
% Push based discovery
In a push-based environment, services only need to know the address of the monitoring service to push their data to the storage \cite{Farcic2017Toolkit21}.


\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{images/02_theoretical_foundation/monitoring/pull_based}
\caption{Pull-based monitoring approach - Source: Authors own model.}
\label{fig:mon_pull-based}
\end{figure}
% Pull based discovery
A pull-based monitoring tool needs to know the address of each target in the environment.
% Why pull based works best with discovery
The advantage of a pull-based monitoring systems is the simplicity to detect whenever a target has failed or is not available \cite{Farcic2017Toolkit21}.


\subsection{Multi-Dimensional Metrics}
\label{subsec:02_monitoring_db_multi-metrics}
% Why do we need dimensions
For query languages to be effective, metrics need to be dimensional. Metric without dimensions, are limited in their capabilities.
% Dynamic environment
In a dynamic environment, services are dynamically added and removed. Therefore, a dynamic environment needs dynamic analytics where metrics represent all dimension in the environment \cite{Farcic2018Toolkit22}.
% Example
\begin{lstlisting}[frame=single, label=lst:mon_metr_dimless, caption=Example of a dimensionless-metric, captionpos=b]
container_cpu_user_seconds_total
\end{lstlisting}
\begin{lstlisting}[frame=single, label=lst:mon_metr_withdim, caption=Example of a metric with dimensions, captionpos=b]
container_cpu_user_seconds_total{image="spark-worker:3.0.1-hadoop2.7"}
\end{lstlisting}
% Explain
As the exasmple \Lst{lst:mon_metr_dimless} and \Lst{lst:mon_metr_withdim} show, the metric with dimension provide more efficient querieing to gather informations about the environment.


\subsection{Query Language}
Another requirement is a powerful and flexible query language. It should have the ability to query a multi-dimensional data model.
% Aggregations
Furthermore, the query language must allow aggregations on time-series data.
