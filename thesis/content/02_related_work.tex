\chapter{Background and Related Work}
\label{sec:related}
%

This chapter provides background information about ...
\todo{Describe Chapter}

\section{Background}

\subsection{Scalability}
% What is scalability
Scalability defines the ability of a computing system to handle an increasing amount of load \cite{Farcic2017Toolkit21}.
% Why scaling
The main reasing for scaling is High-Availability TOOLKIT 2.1.
% Choose right approach
To choose the right approach of scaling an environment is essential.
% Different kind of scaling
To scale the computing capacity of a system, different approaches exists. A major scaling approach is horizontal scaling.

%% Mehr darüber, warum scaling eigentlich so wichtig ist, und welche probleme man damit löst


\subsubsection{Horizontal Scaling}
% What is horizontal scaling
Horizontal scaling is accomplished by duplicating nodes in the computing environment \cite{Wilder2012CloudPatterns}.
% DIstribution
Dplucation the nodes in a computing environment increases the computational capacity of the environment. In addition, the workload can be distributed across all clones to handle and balance and increasing load of tasks \cite{Wilder2012CloudPatterns, Abbott2015ScalabilityArt}. 
% What about homogeneous nodes
To increase the efficiency of horizontal scaling, all nodes should be homogeneous. Homogeneous nodes are able to perform the same work and response as other nodes \cite{Abbott2015ScalabilityArt}.


\subsubsection{Limitations of Scalability}
The limit of scalability is reached, when a computing system is not able to serve the requests of it`s concurrent users \cite{Wilder2012CloudPatterns}.
% hardware capacity
If the scalability of a computing environment is reached, an option is to add more powerful hardware resources to the system. This approach is called vertical scaling QULLE??. By adding more powerful hardware resources, the point can be reached, where more powerful hardware becomes unaffordable or not available \cite{Wilder2012CloudPatterns}.
% Why horizontal i recommended
To overcome the limits of hardware cpacity, a computing system shuld be designed to scale horizontally in the first place \cite{Abbott2015ScalabilityArt}.


\subsection{Self-Healing Environments}
% Auch über container

\subsection{Monitoring}
% Monitoring should be able to deal with dynanism
Self-healing and self-adopting systems are very dynamic in nature. A monitoring should be able to deal with a dynamic environment.
% Requirements of a monitoring system
The requirements for a monitoring system, that is able to monitor a dynamic changing environment, are the following:
\begin{itemize}
\item An efficient database to store metrics
\item A decentralized way of generating metrics \cite{Farcic2017Toolkit21} % Neu schreiben
\item A multi-dimensional data model \cite{Farcic2017Toolkit21} % Neu schreiben
\item A powerful query language \cite{Farcic2017Toolkit21}
\end{itemize}


\subsubsection{Database}
% TS are needed
Saving continous data needs to be done efficiently. 
For time-based metrics, a time series database is he most effective way to save the data \cite{Farcic2017Toolkit21}. To store a huge amount of data, data is stored in a very compact format.


\subsubsection{Metrics}
% Why do we need dimensions
For query languages to be effective, metrics need to be dimensional. Metric without dimensions, are limited in their capabilities.
% Dynamic environment
In a dynamic environment, services are dynamically added and removed. Therefore, a dynamic environment needs dynamic analytics where metrics represent all dimension in the environment \cite{Farcic2018Toolkit22}.
% Example
\begin{lstlisting}[frame=single, label=lst:mon_metr_dimless, caption=Example of a dimensionless-metric, captionpos=b]
container_memory_usage
\end{lstlisting}
\begin{lstlisting}[frame=single, label=lst:mon_metr_withdim, caption=Example of a metric with dimensions, captionpos=b]
container_memory_usage{service="my_service"}
\end{lstlisting}
% Explain
As the exasmple \Lst{lst:mon_metr_dimless} and \Lst{lst:mon_metr_withdim} show, the metric with dimension provide more efficient querieing to gather informations about the environment.


\subsubsection{Data Model}


\subsubsection{Query Model}


\subsubsection{Choosing a Monitoring Tool}
Graphite or Prometheus, Prometheus it its!




% ===========================================
% ===========================================
\section{Related Work}
\subsection{Elastic Environments}
% State of the art monitoring
In recent years, container technologies have been used efficiently in complex IT environments. Dynamic scaling of containerized applications is an active area of research. The studied research can be divided in two parts. 


\subsubsection{Architecture}
% A review of auto-scaling techniques for elastic application in cloud environments
\paragraph{} In the work by Lorido-Botrán et al.  they reviewed state-of-the-art literatures about auto-scaling and proposed a process for auto-scaling homogeneous elastic applications. They mentioned three different problems, auto-scaler face while remaining the Quality of Service (QoS): Under-provisioning, over-provisioning and oscillation. Under-provisioning refers to, if not enough resources are available, over-provisioning means that more resources are available than needed and oscillation occurs when the environment gets scaled too quickly before the impact is clear. They mentioned the MAPE-Loop which consists of four different parts: Monitor, Analyze, Plan and Execute.  The Auto-Scaler is part 


\subsubsection{Auto-Scaler}
% Application deployment using containers with auto-scaling for microservices in cloud environment
\paragraph{}Srirama et al. \citep{Srirama2020AppDeplyCont} designed a heuristic-based auto-scaling strategy for container-based microservices in a cloud environment. The purpose of the auto-scaling strategy was to balance the overall resource utilization across microservices in the environment.
% Results
The proposed auto-scaling strategy performed better results than state-of-the-art algorithms in processing time, processing cost and resource utilization. The processing cost of microservices could be reduced by 12-20\% and the CPU and memory utilization of cloud-servers have been maximized by 9-15\% and 10-18\%.


% Comparison of auto-scaling techniques for cloud environments
\paragraph{}Lorido-Botrán et al.  \cite{Botran2013AutoScalingComp} compared different representative auto-scaling techniques in a simulation in terms of cost and SLO violations. They compared load balancing with static threshold-based rules, reactive and proactive techniques based on CPU load.
Load balancing is based on static rules defining the upper and lower thresholds of a specific load. For example \textit{if CPU > 80\% then scale-out; if CPU < 20\% then scale-in}. The difficulty of this technique is to set the ideal rules. False rules can lead to bad performance. Proactive techniques try to predict the future values of performance metrics based on historical data. Reactive techniques are based on control theory to automate the systems management. In Addition, the authors proposed a new auto-scaling technique. To overcome the difficulties of static thresholds, the authors proposed a new auto-scaling technique using rules with dynamic thresholds. The results showed, that for auto-scaling techniques to scale well, it highly depends on parameter tuning. The best result was achieved with proactive results with a minimum threshold of 20\% and a maximum threshold of 60\%.


\subsubsection{Auto-Scaling Algorithms}
% Delivering elastic ...
\paragraph{}Barna et al. \cite{Barna2017ElasticContainerApps} proposed an autonomic scaling architecture approach for containerized microservices. Their approach focused on creating an autonomic management system, following the autonomic computing concept \cite{Kephart2003VisionComputing}, using a self-tuning performance model. The demonstrated architecture frequently monitors the environment and gathers performance metrics from components. It has the ability to analyze the data and dynamically scale components. In addition, to determine if a scaling action is needed, they proposed the \textit{Scaling Heat Algorithm}. The Scaling Heat Algorithm is used to prevent unnecessary scaling actions, which can throw the environment temporarily off.


% Auto-scaling of Containers: the Impact of Relative and Absolute Metrics
\paragraph{}Casalicchio et al. \cite{Casalicchio2017AutoScaleCont} focused on the difference of absolute and relative metrics for container-based auto-scaling algorithms. They analysed the mechanism of the \textit{Kubernetes Horizontal Pod Auto-scaling} (KHPA) algorithm and proposed a new auto-scaling algorithm based on KHPA using absolute metrics called \textit{KHPA-A}. The results showed, that KHPA-A can reduce response time between 0.5x and 0.66x compared to KHPA. In addition, their work proposed an architecture using cAdvisor for collecting container performance metrics, Prometheus for monitoring, alerting and storing time-series data and Grafana for visualizing metrics.


% ===========================================
% ===========================================
\subsection{Heterogenous GPU aware Spark systems}
% Why is GPU needed
Apache Spark is a computing framework that distributes tasks between CPU cores. Data and compute intensive applications profit from GPU acceleration. Therefore, various research projects took effort to bring GPU acceleration to Apache Spark.


% HeteroSpark
Li et al. \cite{Li2015HeteroSpark} developed a middleware framework called \textit{HeteroSpark} to enable GPU acceleration on Apache Spark worker nodes. HeteroSpark listens for function calls in Spark applications and invokes the GPU kernel for acceleration. For communication between CPU and GPU, HeteroSpark uses the Java RMI\footnote{Java Remote Method Invocation} API to send data from the CPU JVM to the GPU JVM for execution.
% Design
The design provides a plug-n-play approach and an API for the user to call functions with GPU support.
% Results
Overall, HeteroSpark is able to achieve a 18x speed-up for various Machine Learning applications running on Apache Spark.


% HetSpark
Klodjan et al. \cite{Klodjan2018HetSpark} introduced HetSpark a heterogeneous modification of Apache Spark.
% The goal
HetSpark extends Apache Spark with two executors, a GPU accelerated executor and a commodity class. The GPU accelerated executor is based on VineTalk\cite{Mavridis2017VineTalk} for GPU acceleration.
% Results
The authors observed, that for compute intensive tasks GPU accelerated executers are preferable while for linear tasks CPU-only accelerators should be used.


% Spark-GPU
Yuan et al. \cite{Yuan2016SparkGPU} proposed SparkGPU to enable parallel processing with GPUs in Apache Spark and contributes to achieve high performance and high throughput in Apache Spark applications.
SparkGPU extends Apache Sparks to determine the suitability of parallel-processing for a task to enable task scheduling between CPU and GPU. 
SparkGPU accomplished to improve the performance of machine learning algorithms up to 16.13x and SQL query execution performance up to 4.83x.


