%% Dokumentenklasse (Koma Script) -----------------------------------------
\documentclass[%
   %draft,     % Entwurfsstadium
   final,      % fertiges Dokument
	 % --- Paper Settings ---
   paper=a4,% [Todo: add alternatives]
   paper=portrait, % landscape
   pagesize=auto, % driver
   % --- Base Font Size ---
   fontsize=12pt,%
	 % --- Koma Script Version ---
   version=last, %
 ]{scrbook} % Classes: scrartcl, scrreprt, scrbook

% Encoding der Dateien (sonst funktionieren Umlaute nicht)
\usepackage{listings}
\usepackage{booktabs}
%\usepackage{acro}
%\usepackage[ruled,vlined]{algorithm2e}
\usepackage[utf8]{inputenc}
\usepackage[htt]{hyphenat}

%%% Preambel
\input{preambel/settings}
\input{preambel/preambel}
%
%%%% Neue Befehle
\input{macros/abbrev}
\input{macros/math}
\input{macros/environments}
\input{macros/newcommands}
\input{macros/tikz}
%%% Silbentrennung
\input{preambel/Hyphenation}

%%% Wasserzeichen "Entwurf"
\draft{%
\AddToShipoutPicture{%
  \setlength{\unitlength}{1cm}
  %\ifthenelse{\equal{\value{page}}{1}}{}{%
  \ifthenelse{\isodd{\value{page}}}
  	{\put(19,14.98){% Mitte rechts von A4 (21cm max 29.7cm)
      \makebox(0,0){\rotatebox{90}{\textcolor[gray]{0.8}{\fontsize{4cm}{4cm}\selectfont{\rm{Entwurf}}}}}
    }}
    {\put(2,14.98){ % Mitte links von A4 (21cm max 29.7cm)
        	\makebox(0,0){\rotatebox{-90}{\textcolor[gray]{0.8}{\fontsize{4cm}{4cm}\selectfont{\rm{Entwurf}}}}}
    }}
  }
%}
}

%%% Design für listings
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{codestyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    frame=lines
}

\lstset{style=codestyle}


%%% Formatierung
%\clubpenalty=1000000
%\widowpenalty=1000000
%\brokenpenalty=1000000
%\finalhyphendemerits=1000000
%\renewcommand{\baselinestretch}{1.7}

%% Dokument Beginn %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% - Deckblatt,
% - Inhaltsverzeichnis,
% - Hauptteil gegliedert z.B. in
%   Einleitung, Grundlagen, Experimente, Ergebnisse, Zusammenfassung
% - Literaturverzeichnis,
% - Abbildungsverzeichnis (ggf.),
% - Tabellenverzeichnis (ggf.),
% - Abkürzungsverzeichnis (ggf.),
% - Formelverzeichnis (ggf.),
% - Anhang, (nicht mehr Bestandteil der Arbeit! Wird daher nicht bewertet)
% - Erklärung der Urheberschaft,

\title{Automated Deployment of Machine Learning Applications on a Scalable Heterogeneous GPU-Accelerated Apache Spark Cluster}
\author{Marcel Pascal Stolin}
\matrikel{32168}
\thesis{Bachelor Thesis}
\geburtsdatum{03.04.1993}
\geburtsort{Kamen}
\abgabedatum{\today}
\supervisor{M.Sc. Christoph Hennebold}

\zusammenfassung{Die wachsende Rechenkomplexität beim trainieren von Machine Learning-Modellen mit Big Data erfordert eine Erhöhung der Skalierbarkeit von Rechenclustern. In verteilten Systemen kann ein Rechencluster dynamisch skaliert werden, sobald eine Leistungsschwelle erreicht wird. Ein beliebtes Framework für verteiltes Rechnen ist Apache Spark, das die parallele Datenverarbeitung auf einem Rechencluster ermöglicht. Mit der jüngsten Entwicklung der RAPIDS-Plugin-Suite kann die Rechenleistung weiter gesteigert werden, indem Apache Spark die Nutzung von GPUs ermöglicht wird.
Außerdem ist durch die Popularität der DevOps-Kultur die Automatisierung von Entwicklungsprozessen zu einem trivialen Prozess geworden. Das Training von Machine Learning-Modellen ist ein komplexer Prozess, der mithilfe einer CI-Pipeline automatisiert werden kann.
Ziel dieser Arbeit ist es, ein Entwurf und die Implementierung einer skalierbaren verteilten Rechenumgebung für das Training von Machine Learning-Modellen mit Apache Spark vorzustellen. Dazu wird die Leistung des Apache Spark-Clusters durch die Nutzung von GPUs unter Verwendung der RAPIDS-Plugin-Suite erhöht. Ein \textit{Auto-Scaler}, der die Anzahl der Apache Spark-Worker skaliert, wird implementiert und der Rechenumgebung hinzugefügt, um die Skalierbarkeit weiter zu erhöhen. Darüber hinaus wird ein CI-Pipeline-Entwurf und eine Implementierung mittels GitLab CI/CD vorgestellt, die das Training einer Machine Learning-Anwendung auf Apache Spark automatisiert. Die Leistung der Rechenumgebung wird mit zwei unterschiedlichen Machine Learning-Algorithmen bewertet. Die Ergebnisse zeigen, dass die Leistung des Apache Spark-Clusters durch die Verwendung von GPUs signifikant verbessert wurde, während die \textit{Auto-Scaler}-Implementierung die Leistung des Apache Spark-Clusters nicht erhöht hat.\newpage}
\abstract{The growing computational complexity of training Machine Learning models on Big Data requires increasing the scalability of computing clusters. With distributed computing, a cluster can dynamically be scaled whenever a performance threshold is reached. A popular framework for distributed computing is Apache Spark, which enables parallel data processing on a large computing cluster. With the recent development of the RAPIDS plugin suite, the computational power can further be increased by enabling Apache Spark to leverage GPUs. Furthermore, due to DevOps culture popularity, automating development processes has become a trivial process. The training of machine learning models is a complex process that can be automated using a CI pipeline. This thesis aims to present a design and implementation of a scalable distributed computing environment for training Machine Learning models using Apache Spark. Therefore, the Apache Spark cluster's performance is increased by leveraging GPUs using the RAPIDS plugin suite. An \textit{Auto-Scaler} that scales the number of Apache Spark workers is implemented and added to the computing environment to increase the scalability further. Additionally, a CI pipeline design and implementation using GitLab CI/CD is introduced, which automates the deployment of an application to the Apache Spark cluster. The performance of the computing environment is evaluated using two different Machine Learning algorithms. The results show that the performance of the Apache Spark cluster has significantly been improved using GPUs, whereas the \textit{Auto-Scaler} implementation did not increase the performance of the Apache Spark cluster.}

\begin{document}
% Deckblatt
\input{content/Titel}
\frontmatter

\cleardoublepage
\input{content/Erklaerung}

\cleardoublepage
\input{content/Zusammenfassung}

\cleardoublepage
% Abbildungs- und Tabellenverzeichnis
\listoffigures
\listoftables
\lstlistoflistings
% Inhaltsverzeichnis in den PDF-Links eintragen
% \pdfbookmark[1]{Inhaltsverzeichnis}{toc}
\tableofcontents

\input{content/Notation}

% Hauptteil
\mainmatter

%\iffalse
\input{content/01_intro}
\input{content/02_theoretical_foundation}
\input{content/03_related_work}
\input{content/04_technical_background}
\input{content/05_design}
\input{content/06_implementation}
\input{content/07_evaluation}
\input{content/08_conclusion_outlook}
%\fi

% Anhang (Bibliographie darf im deutschen nicht in den Anhang!)
\bibliography{literatur}
%\nocite{*}
\clearpage

% Anhang
\appendix
% 'Anhang' ins Inhaltsverzeichnis
\phantomsection
\addcontentsline{toc}{part}{Appendix}
\input{content/appendix}

\IfDefined{printindex}{\printindex}
\IfDefined{printnomenclature}{\printnomenclature}



%% Dokument ENDE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}

